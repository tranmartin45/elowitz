{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory containing the images\n",
    "data_dir = '/Volumes/martin/A08_A09_test'\n",
    "\n",
    "# glob string for images\n",
    "im_glob = os.path.join(data_dir, 'Round1_max_composite.tif')\n",
    "\n",
    "# Get list of images\n",
    "im_list = sorted(glob.glob(im_glob))\n",
    "\n",
    "im_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each .tif file has 72 pictures. There are 6 conditions with 12 positions each. The first two area are irrelevant. For the last four, there is the A8 ABE, A8 pUC19, A9 ABE, and A9 pUC19.\n",
    "\n",
    "There are four readout probes. Generally they correspond to 488 and 561 being for unedit barcode and 594 and 647 being for edited barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data using skimage\n",
    "im = skimage.io.imread(im_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A8_ABE = im[24:36]\n",
    "A8_pUC19 = im[36:48]\n",
    "A9_ABE = im[48:60]\n",
    "A9_pUC19 = im[60:72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i=5 for A8_pUC19\n",
    "\n",
    "i = 0\n",
    "condition = A8_ABE\n",
    "af488 = condition[i][0]\n",
    "af561 = condition[i][1]\n",
    "af594 = condition[i][2]\n",
    "af633 = condition[i][3]\n",
    "cfp = condition[i][4]\n",
    "dapi = condition[i][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af561 = register_images(af488, af561)\n",
    "af594 = register_images(af488, af594)\n",
    "af633 = register_images(af488, af633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imadjust(img, lower_bound=0.05, upper_bound=99.95):\n",
    "    lower = np.percentile(img, lower_bound)\n",
    "    upper = np.percentile(img, upper_bound)\n",
    "    out = (img - lower) * (255 / (upper - lower))\n",
    "    return np.clip(out, 0, 255, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_adj = imadjust(af488)\n",
    "af561_adj = imadjust(af561)\n",
    "af594_adj = imadjust(af594)\n",
    "af633_adj = imadjust(af633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_g, af561_g, af594_g = filt_gauss(af488_adj, af561_adj, af594_adj, 1.5)\n",
    "af633_g, cfp_g, dapi_g = filt_gauss(af633_adj, cfp, dapi, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = threshold_otsu(dapi_g)\n",
    "print(threshold, 'is where the cutoff point is.')\n",
    "dapi_bw = dapi_g > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_labels, df_dapi, dapi_area, dapi_distance, dapi_markers = ws(dapi_bw, 2, np.ones((45,45)), 2000, dapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(show_three_ims(dapi, dapi_bw, dapi_labels,\n",
    "                             cmap=[None, None, colorcet.b_glasbey_hv]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will apply a LoG filter. This filter detects edges, which are defined by areas of sudden peaks or valleys in the gradient (first derivative) of the pixel intensity values. A peak or a valley in the first derivative means there is a zero-crossing in the second derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_edge_zero, af488_LoG, af488_edge = log_filter(af488_g, 1.5, 4, 1)\n",
    "af561_edge_zero, af561_LoG, af561_edge = log_filter(af561_g, 1.5, 4, 1)\n",
    "af594_edge_zero, af594_LoG, af594_edge = log_filter(af594_g, 1.5, 4, 1)\n",
    "af633_edge_zero, af633_LoG, af633_edge = log_filter(af633_g, 1.5, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result\n",
    "'''\n",
    "bokeh.io.show(show_four_ims(af488_g, af488_LoG, af488_edge, af488_edge_zero,\n",
    "                            titles=[\"488\", \"LoG\", \"edge\", \"zero\"]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result\n",
    "bokeh.io.show(show_four_ims(af488_g, af488_edge_zero, af594_g, af594_edge_zero,\n",
    "                            titles=[\"488\", \"488\", \"594\", \"594\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result\n",
    "bokeh.io.show(show_four_ims(af594_g, af594_edge_zero, af633_g, af633_edge_zero,\n",
    "                            titles=[\"561\", \"561\", \"633\", \"633\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will skeletonize to get single pixel edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Skeletonize edges\n",
    "af488_edge_sk = skimage.morphology.skeletonize(af488_edge_zero)\n",
    "af561_edge_sk = skimage.morphology.skeletonize(af561_edge_zero)\n",
    "af594_edge_sk = skimage.morphology.skeletonize(af594_edge_zero)\n",
    "af633_edge_sk = skimage.morphology.skeletonize(af633_edge_zero)\n",
    "\n",
    "# See result\n",
    "bokeh.io.show(show_two_ims(af488_g, af488_edge_sk, titles=[\"original\", \"edges\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will fill the holes created from the edges. Note that this will not fill holes that have any openings in them, even if the openings are very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill holes\n",
    "af488_bw = ndi.morphology.binary_fill_holes(af488_edge_sk)\n",
    "af561_bw = ndi.morphology.binary_fill_holes(af561_edge_sk)\n",
    "af594_bw = ndi.morphology.binary_fill_holes(af594_edge_sk)\n",
    "af633_bw = ndi.morphology.binary_fill_holes(af633_edge_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result\n",
    "bokeh.io.show(show_four_ims(af488_g, af488_bw, af594_g, af594_bw,\n",
    "                            titles=[\"488\", \"488\", \"594\", \"594\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove small objects. Note that this removes any objects that are not filled as well and will remove dots if they are not already filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove small objectes that are not bacteria\n",
    "af488_bw = skimage.morphology.remove_small_objects(af488_bw, min_size=10)\n",
    "af561_bw = skimage.morphology.remove_small_objects(af561_bw, min_size=10)\n",
    "af594_bw = skimage.morphology.remove_small_objects(af594_bw, min_size=10)\n",
    "af633_bw = skimage.morphology.remove_small_objects(af633_bw, min_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_labels, df_af488, af488_area, af488_distance, af488_markers = ws(af488_bw, 1, np.ones((8,8)), 10, af488)\n",
    "af561_labels, df_af561, af561_area, af561_distance, af561_markers = ws(af561_bw, 1, np.ones((8,8)), 10, af561)\n",
    "af594_labels, df_af594, af594_area, af594_distance, af594_markers = ws(af594_bw, 1, np.ones((8,8)), 10, af594)\n",
    "af633_labels, df_af633, af633_area, af633_distance, af633_markers = ws(af633_bw, 1, np.ones((8,8)), 10, af633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bokeh.io.show(show_four_ims(af488_g, af488_labels, af594_g, af594_labels,\n",
    "                            titles=[\"488\", \"488\", \"594\", \"594\"],\n",
    "                            cmap=[None, colorcet.b_glasbey_hv, None, colorcet.b_glasbey_hv]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The watershed works fine but results in irregularly shaped dots. I will address this by using the binary_opening tool, followed by erosion, and a relabel step. This will result in eroded dots that have a more typical circular shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = skimage.morphology.disk(1)\n",
    "af488_open = skimage.morphology.binary_opening(af488_labels, selem)\n",
    "af561_open = skimage.morphology.binary_opening(af561_labels, selem)\n",
    "af594_open = skimage.morphology.binary_opening(af594_labels, selem)\n",
    "af633_open = skimage.morphology.binary_opening(af633_labels, selem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = skimage.morphology.disk(1)\n",
    "af488_e = label(skimage.morphology.erosion(af488_open, selem))\n",
    "af561_e = label(skimage.morphology.erosion(af561_open, selem))\n",
    "af594_e = label(skimage.morphology.erosion(af594_open, selem))\n",
    "af633_e = label(skimage.morphology.erosion(af633_open, selem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bokeh.io.show(show_six_ims(af488_g, af488_labels, af488_e, af594_g, af594_labels, af594_e,\n",
    "                            titles=[\"488\", \"488\", \"488\", \"594\", \"594\", \"594\"],\n",
    "                            cmap=[None, colorcet.b_glasbey_hv, colorcet.b_glasbey_hv,\n",
    "                                  None, colorcet.b_glasbey_hv, colorcet.b_glasbey_hv]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will create an OR mask. I will relabel this as well, as the logical_or function results in a binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "af488_594 = label(np.logical_or(af488_e, af594_e))\n",
    "af561_633 = label(np.logical_or(af561_e, af633_e))\n",
    "\n",
    "bokeh.io.show(show_five_ims(af488_e, af594_e, af488_594, af488_g, af594_g,\n",
    "                             titles=['488', '594', 'OR', '488', '594'], \n",
    "                             cmap=[colorcet.b_glasbey_hv, colorcet.b_glasbey_hv, colorcet.b_glasbey_hv, None, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the OR statement results in some dots that overlap. I will plot a histogram to look at the typical dot sizes in the OR mask so that I can choose a maximum size threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = skimage.measure.regionprops_table(af488_594, properties=('label',\n",
    "                                                                 'centroid',\n",
    "                                                                 'area',\n",
    "                                                                 ))\n",
    "df = pd.DataFrame(props)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Histogram(data=np.histogram(df['area'], bins=1000),\n",
    "             kdims=['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram, I can see that most of the dot sizes are less than 75 (total area). I will use this as my maximum size threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['area'] < 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to remove large objects\n",
    "def remove_large(label_image, max_size, df):\n",
    "    '''\n",
    "    Function to remove large segments from image.\n",
    "    \n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_image : array\n",
    "        watershed image with labels\n",
    "    max_size : int\n",
    "        remove all segments larger than this size. Default is 1000\n",
    "    df : DataFrame\n",
    "        DataFrame of watershed image\n",
    "    \n",
    "    --------\n",
    "    Output\n",
    "    --------\n",
    "    large_sub : array\n",
    "        image with large segments subtracted\n",
    "    df_large : DataFrame\n",
    "        DataFrame with large segments subtracted\n",
    "        \n",
    "    '''\n",
    "    if label_image.sum() != 0:\n",
    "        empty_array = np.zeros_like(label_image)\n",
    "        max_size = max_size\n",
    "\n",
    "        for i, label in enumerate(df.loc[df.loc[:, 'area'] > max_size]['label']):\n",
    "            x = label_image == label\n",
    "            y = x * label\n",
    "            empty_array += y\n",
    "\n",
    "        large_sub = label_image - empty_array\n",
    "    return large_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_594_largesub = remove_large(af488_594, 75, df)\n",
    "af561_633_largesub = remove_large(af561_633, 75, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_594_smallsub = skimage.morphology.remove_small_objects(af488_594_largesub, min_size=4)\n",
    "af561_633_smallsub = skimage.morphology.remove_small_objects(af561_633_largesub, min_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bokeh.io.show(show_four_ims(af488_594, af488_594_smallsub, af488_g, af594_g,\n",
    "                             titles=['OR', 'OR large sub', '488', '594'], \n",
    "                             cmap=[colorcet.b_glasbey_hv, colorcet.b_glasbey_hv, None, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af488_594_filt = af488_594_smallsub * dapi_bw\n",
    "af561_633_filt = af561_633_smallsub * dapi_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bokeh.io.show(show_two_ims(af488_594_largesub, af488_594_smallsub,\n",
    "                             titles=['OR large sub', 'OR large and small sub'], \n",
    "                             cmap=[colorcet.b_glasbey_hv, colorcet.b_glasbey_hv]))\n",
    "                             '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloc(large_sub, unedited, edited):\n",
    "    '''\n",
    "    Function to get all nuclei with mean intensity for each channel. Can do two channels.\n",
    "    \n",
    "    ---------\n",
    "    Parameters\n",
    "    ---------\n",
    "    large_sub : array\n",
    "        OR watershed image with small and large segments subtracted\n",
    "    unedited : array\n",
    "        raw intensity image\n",
    "    edited : array\n",
    "        raw intensity image\n",
    "    \n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "    df_co : DataFrame\n",
    "        DataFrame with all dots with mean intensity for each channel.\n",
    "    '''\n",
    "\n",
    "    props_unedited = skimage.measure.regionprops_table(large_sub, intensity_image=unedited, properties=('label',\n",
    "                                                                                             'centroid',\n",
    "                                                                                             'area',\n",
    "                                                                                             'mean_intensity'))\n",
    "    df_unedited = pd.DataFrame(props_unedited)\n",
    "    df_unedited['sum_intensity'] = df_unedited['area']*df_unedited['mean_intensity']\n",
    "    \n",
    "\n",
    "    props_edited = skimage.measure.regionprops_table(large_sub, intensity_image=edited, properties=('label',\n",
    "                                                                                                 'centroid',\n",
    "                                                                                                 'area',\n",
    "                                                                                                 'mean_intensity'))\n",
    "    df_edited = pd.DataFrame(props_edited)\n",
    "    df_edited['sum_intensity'] = df_edited['area']*df_edited['mean_intensity']\n",
    "    \n",
    "    mean_unedited_vals = df_unedited['mean_intensity'].values\n",
    "    mean_edited_vals = df_edited['mean_intensity'].values\n",
    "    \n",
    "    sum_unedited_vals = df_unedited['sum_intensity'].values\n",
    "    sum_edited_vals = df_edited['sum_intensity'].values\n",
    "    \n",
    "    data = {'Unedited mean intensity': mean_unedited_vals, \n",
    "            'Edited mean intensity': mean_edited_vals,\n",
    "            'Unedited sum intensity': sum_unedited_vals,\n",
    "            'Edited sum intensity': sum_edited_vals}\n",
    "    df_co = pd.DataFrame(data)\n",
    "    return df_co, df_unedited, df_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc1, df_bc1_unedited, df_bc1_edited = coloc(af488_594_filt, af488, af594)\n",
    "df_bc2, df_bc2_unedited, df_bc2_edited = coloc(af561_633_filt, af561, af633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc1_unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc1['ln(intensity) of unedited probe'] = np.log(df_bc1['Unedited sum intensity'])\n",
    "df_bc1['ln(intensity) of edited probe'] = np.log(df_bc1['Edited sum intensity'])\n",
    "df_bc2['ln(intensity) of unedited probe'] = np.log(df_bc2['Unedited sum intensity'])\n",
    "df_bc2['ln(intensity) of edited probe'] = np.log(df_bc2['Edited sum intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Points(data=df_bc1,\n",
    "          kdims=['Unedited mean intensity', 'Edited mean intensity'],\n",
    "          label='bc1'\n",
    ").opts(\n",
    "    logy=True, \n",
    "    logx=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Points(data=df_bc1,\n",
    "          kdims=['ln(intensity) of unedited probe', 'ln(intensity) of edited probe'],\n",
    "          label='Label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Points(data=df_bc2,\n",
    "          kdims=['Unedited mean intensity', 'Edited mean intensity'],\n",
    "          label='bc2'\n",
    ").opts(\n",
    "    logy=True, \n",
    "    logx=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Points(data=df_bc2,\n",
    "          kdims=['Unedited sum intensity', 'Edited sum intensity'],\n",
    "          label='Label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
